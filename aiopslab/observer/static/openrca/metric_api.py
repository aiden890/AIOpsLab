# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

"""OpenRCA Metric Observer API - reads metric data from CSV files."""

import logging
from pathlib import Path
from datetime import datetime
from typing import Optional
import pandas as pd

from aiopslab.observer.static.base import StaticObserverBase

logger = logging.getLogger(__name__)


class OpenRCAMetricAPI(StaticObserverBase):
    """
    Observer API for OpenRCA metric telemetry.

    Reads metric data from CSV files generated by the static replayer.
    Supports time-windowed queries and filtering by metric name and service.
    """

    def __init__(self, output_path: Path):
        """
        Initialize OpenRCA Metric API.

        Args:
            output_path: Path to telemetry output directory containing metric.csv
        """
        super().__init__(output_path)
        self.telemetry_type = 'metric'

        # Expected schema for OpenRCA metric data
        self.expected_columns = [
            'timestamp', 'cmdb_id', 'kpi_name', 'value'
        ]

    def get_csv_path(self) -> Path:
        """Return path to metric.csv file."""
        return self.output_path / 'metric.csv'

    def extract_data(self, start_time: datetime, end_time: datetime, **filters) -> pd.DataFrame:
        """
        Extract metric data within time window with optional filters.

        Args:
            start_time: Start of time window
            end_time: End of time window
            **filters: Optional filters (cmdb_id, kpi_name)

        Returns:
            DataFrame with filtered metric data
        """
        return self.query_metrics(
            start_time=start_time,
            end_time=end_time,
            cmdb_id=filters.get('cmdb_id'),
            kpi_name=filters.get('kpi_name')
        )

    def query_metrics(
        self,
        start_time: datetime,
        end_time: datetime,
        cmdb_id: Optional[str] = None,
        kpi_name: Optional[str] = None
    ) -> pd.DataFrame:
        """
        Query metric data within a time window with optional filters.

        Args:
            start_time: Start of time window
            end_time: End of time window
            cmdb_id: Optional filter for specific service/component
            kpi_name: Optional filter for specific KPI/metric name

        Returns:
            DataFrame with metrics matching the query

        Raises:
            ValueError: If start_time > end_time
        """
        # Validate time range
        if start_time > end_time:
            raise ValueError(f"start_time ({start_time}) must be <= end_time ({end_time})")

        logger.info(f"Querying metrics: {start_time} to {end_time}")
        if cmdb_id:
            logger.info(f"  Filter: cmdb_id={cmdb_id}")
        if kpi_name:
            logger.info(f"  Filter: kpi_name={kpi_name}")

        # Read CSV with time filtering
        df = self._read_csv_with_time_filter(start_time, end_time)

        if df.empty:
            logger.info("No metrics found in time window")
            return df

        # Apply additional filters
        if cmdb_id:
            df = df[df['cmdb_id'] == cmdb_id]

        if kpi_name:
            df = df[df['kpi_name'] == kpi_name]

        logger.info(f"Found {len(df)} metric records")
        return df

    def get_metric_names(self, cmdb_id: Optional[str] = None) -> list[str]:
        """
        Get list of all metric/KPI names, optionally filtered by service.

        Args:
            cmdb_id: Optional filter for specific service/component

        Returns:
            List of unique metric names
        """
        csv_path = self.get_csv_path()

        if not csv_path.exists():
            logger.warning(f"Metric CSV not found: {csv_path}")
            return []

        try:
            # Read necessary columns
            if cmdb_id:
                df = pd.read_csv(csv_path, usecols=['cmdb_id', 'kpi_name'])
                df = df[df['cmdb_id'] == cmdb_id]
            else:
                df = pd.read_csv(csv_path, usecols=['kpi_name'])

            metric_names = df['kpi_name'].unique().tolist()
            logger.info(f"Found {len(metric_names)} unique metric names")
            return metric_names
        except Exception as e:
            logger.error(f"Error reading metric names: {e}")
            return []

    def get_time_series(
        self,
        kpi_name: str,
        cmdb_id: str,
        start_time: datetime,
        end_time: datetime
    ) -> pd.DataFrame:
        """
        Get time series data for a specific metric and service.

        Args:
            kpi_name: The metric/KPI name
            cmdb_id: The service/component ID
            start_time: Start of time window
            end_time: End of time window

        Returns:
            DataFrame with timestamp and value columns sorted by time
        """
        logger.info(f"Getting time series for {cmdb_id}/{kpi_name}")

        # Query with filters
        df = self.query_metrics(
            start_time=start_time,
            end_time=end_time,
            cmdb_id=cmdb_id,
            kpi_name=kpi_name
        )

        if df.empty:
            return df

        # Sort by timestamp for time series
        df = df.sort_values('timestamp').reset_index(drop=True)

        logger.info(f"Time series has {len(df)} data points")
        return df[['timestamp', 'datetime', 'value']]

    def get_services(self) -> list[str]:
        """
        Get list of all services (cmdb_ids) in the metric data.

        Returns:
            List of unique service names
        """
        csv_path = self.get_csv_path()

        if not csv_path.exists():
            logger.warning(f"Metric CSV not found: {csv_path}")
            return []

        try:
            # Read cmdb_id column only
            df = pd.read_csv(csv_path, usecols=['cmdb_id'])
            services = df['cmdb_id'].unique().tolist()
            logger.info(f"Found {len(services)} unique services in metrics")
            return services
        except Exception as e:
            logger.error(f"Error reading services from metric CSV: {e}")
            return []
